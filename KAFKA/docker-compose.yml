version: '3.9'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.3
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 20s
      timeout: 5s
      retries: 3
      start_period: 10s
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-logs:/var/lib/zookeeper/log
    networks:
      - kafka-network

  broker:
    image: confluentinc/cp-kafka:7.5.3
    hostname: broker
    container_name: broker
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "29092:29092"
      - "9101:9101"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://broker:29092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_HEAP_OPTS: "-Xmx1G -Xms1G"
      KAFKA_NUM_PARTITIONS: 3
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 20s
      timeout: 5s
      retries: 3
      start_period: 20s
    volumes:
      - kafka-data:/var/lib/kafka/data
    networks:
      - kafka-network

  schema-registry:
    image: confluentinc/cp-schema-registry:7.5.3
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      broker:
        condition: service_healthy
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker:29092'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_HEAP_OPTS: "-Xmx512M -Xms512M"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/subjects"]
      interval: 20s
      timeout: 5s
      retries: 3
      start_period: 20s
    networks:
      - kafka-network

  kafka-rest:
    image: confluentinc/cp-kafka-rest:7.5.3
    hostname: kafka-rest
    container_name: kafka-rest
    depends_on:
      broker:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    ports:
      - "8082:8082"
    environment:
      KAFKA_REST_HOST_NAME: kafka-rest
      KAFKA_REST_BOOTSTRAP_SERVERS: 'broker:29092'
      KAFKA_REST_LISTENERS: "http://0.0.0.0:8082"
      KAFKA_REST_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      KAFKA_REST_HEAP_OPTS: "-Xmx512M -Xms512M"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8082/topics"]
      interval: 20s
      timeout: 5s
      retries: 3
      start_period: 20s
    networks:
      - kafka-network

  connect:
    image: confluentinc/cp-kafka-connect:7.5.3
    hostname: connect
    container_name: connect
    depends_on:
      broker:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'broker:29092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "true"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components,/etc/kafka-connect/custom-plugins"
      CONNECT_HEAP_OPTS: "-Xmx1G -Xms1G"
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/connectors"]
      interval: 20s
      timeout: 5s
      retries: 3
      start_period: 120s
    volumes:
      - connect-data:/usr/share/confluent-hub-components
      - ./custom-plugins:/etc/kafka-connect/custom-plugins
      - ./jdbc-drivers:/usr/share/confluent-hub-components/jdbc-drivers
    command:
      - bash
      - -c
      - |
        echo "Creating Kafka Connect required topics with cleanup.policy=compact..."
        # Create the topics with correct cleanup policy BEFORE Connect starts
        kafka-topics --bootstrap-server broker:29092 --create --topic docker-connect-configs --partitions 1 --replication-factor 1 --config cleanup.policy=compact || true
        kafka-topics --bootstrap-server broker:29092 --create --topic docker-connect-offsets --partitions 1 --replication-factor 1 --config cleanup.policy=compact || true
        kafka-topics --bootstrap-server broker:29092 --create --topic docker-connect-status --partitions 1 --replication-factor 1 --config cleanup.policy=compact || true
        
        # Verify the topic has the correct cleanup policy
        CLEANUP_POLICY=$(kafka-configs --bootstrap-server broker:29092 --entity-type topics --entity-name docker-connect-status --describe | grep cleanup.policy | awk '{print $4}')
        if [ "$CLEANUP_POLICY" != "compact" ]; then
            echo "Setting cleanup.policy=compact for docker-connect-status topic..."
            kafka-configs --bootstrap-server broker:29092 --entity-type topics --entity-name docker-connect-status --alter --add-config cleanup.policy=compact
        fi
        
        echo "Installing connectors..."
        mkdir -p /usr/share/confluent-hub-components/jdbc-drivers
        confluent-hub install --no-prompt confluentinc/kafka-connect-jdbc:10.7.4
        confluent-hub install --no-prompt mongodb/kafka-connect-mongodb:1.11.1
        confluent-hub install --no-prompt confluentinc/kafka-connect-elasticsearch:14.0.8
        confluent-hub install --no-prompt confluentinc/kafka-connect-s3:10.5.8
        confluent-hub install --no-prompt debezium/debezium-connector-mysql:2.4.0
        confluent-hub install --no-prompt debezium/debezium-connector-postgresql:2.4.0
        confluent-hub install --no-prompt debezium/debezium-connector-sqlserver:2.4.0
        confluent-hub install --no-prompt debezium/debezium-connector-mongodb:2.4.0
        confluent-hub install --no-prompt confluentinc/kafka-connect-azure-blob-storage:1.6.7
        confluent-hub install --no-prompt confluentinc/kafka-connect-azure-data-lake-gen2-storage:1.6.7
        confluent-hub install --no-prompt confluentinc/kafka-connect-gcs:10.1.1
        
        echo "Downloading JDBC drivers..."
        cd /usr/share/confluent-hub-components/jdbc-drivers
        [ ! -f "postgresql-42.6.0.jar" ] && curl -k -SL "https://jdbc.postgresql.org/download/postgresql-42.6.0.jar" -o postgresql-42.6.0.jar
        [ ! -f "mysql-connector-j-8.0.33.jar" ] && curl -k -SL "https://repo1.maven.org/maven2/com/mysql/mysql-connector-j/8.0.33/mysql-connector-j-8.0.33.jar" -o mysql-connector-j-8.0.33.jar
        [ ! -f "mssql-jdbc-12.4.1.jre11.jar" ] && curl -k -SL "https://github.com/microsoft/mssql-jdbc/releases/download/v12.4.1/mssql-jdbc-12.4.1.jre11.jar" -o mssql-jdbc-12.4.1.jre11.jar
        
        echo "Connector installation complete!"
        echo "Starting Kafka Connect..."
        /etc/confluent/docker/run
    networks:
      - kafka-network

  ksqldb-server:
    image: confluentinc/cp-ksqldb-server:7.5.3
    hostname: ksqldb-server
    container_name: ksqldb-server
    depends_on:
      broker:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
      connect:
        condition: service_healthy
    ports:
      - "8088:8088"
    environment:
      KSQL_BOOTSTRAP_SERVERS: "broker:29092"
      KSQL_HOST_NAME: ksqldb-server
      KSQL_LISTENERS: "http://0.0.0.0:8088"
      KSQL_CACHE_MAX_BYTES_BUFFERING: 0
      KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      KSQL_KSQL_CONNECT_URL: "http://connect:8083"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_REPLICATION_FACTOR: 1
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: 'true'
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: 'true'
      KSQL_HEAP_OPTS: "-Xmx1G -Xms1G"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8088/healthcheck"]
      interval: 20s
      timeout: 5s
      retries: 3
      start_period: 30s
    networks:
      - kafka-network

  ksqldb-cli:
    image: confluentinc/cp-ksqldb-cli:7.5.3
    container_name: ksqldb-cli
    depends_on:
      ksqldb-server:
        condition: service_healthy
    entrypoint: /bin/sh
    tty: true
    networks:
      - kafka-network

  control-center:
    image: confluentinc/cp-enterprise-control-center:7.5.3
    hostname: control-center
    container_name: control-center
    depends_on:
      broker:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
      connect:
        condition: service_healthy
      ksqldb-server:
        condition: service_healthy
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker:29092'
      CONTROL_CENTER_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      CONTROL_CENTER_CONNECT_URL: 'http://connect:8083'
      CONTROL_CENTER_KSQL_URL: 'http://ksqldb-server:8088'
      CONTROL_CENTER_KSQL_ADVERTISED_URL: 'http://ksqldb-server:8088'
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_HEAP_OPTS: "-Xmx1G -Xms1G"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9021"]
      interval: 20s
      timeout: 5s
      retries: 3
      start_period: 45s
    volumes:
      - control-center-data:/var/lib/confluent-control-center
    networks:
      - kafka-network

volumes:
  zookeeper-data:
  zookeeper-logs:
  kafka-data:
  connect-data:
  control-center-data:

networks:
  kafka-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16